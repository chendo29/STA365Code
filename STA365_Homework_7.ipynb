{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyModtvLroYFaAZFcKPC5Wcs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chendo29/STA365Code/blob/main/STA365_Homework_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 7"
      ],
      "metadata": {
        "id": "NFYE6nGfrxhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\newcommand{\\N}{\\mathbb{N}}  % Natural numbers\n",
        "\\newcommand{\\Z}{\\mathbb{Z}}  % Integers\n",
        "\\newcommand{\\R}{\\mathbb{R}}  % Real numbers\n",
        "\\newcommand{\\C}{\\mathbb{C}}  % Complex numbers\n",
        "\\newcommand{\\Q}{\\mathbb{Q}}  % Rational numbers\n",
        "\\newcommand{\\p}{\\partial}  %  for partial derivatives\n",
        "\\newcommand{\\f}{\\frac} % fractions\n",
        "\\newcommand{\\mb}{\\mathbf}\n",
        "\\newcommand{\\tr}{\\mathrm{tr}}\n",
        "%\\newcommand{\\det}{\\mathrm{det}}\n",
        "\\newcommand{\\ra}{\\Rightarrow}\n",
        "\\newcommand{\\upa}{\\uparrow}\n",
        "\\newcommand{\\lra}{\\Leftrightarrow}\n",
        "\\newcommand{\\lan}{\\langle}\n",
        "\\newcommand{\\ran}{\\rangle}\n",
        "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
        "\\newcommand{\\inn}[1]{\\lan#1\\ran}\n",
        "\\newcommand{\\floor}[1]{\\lfloor#1\\rfloor}\n",
        "\\newcommand{\\ol}{\\overline}\n",
        "\\newcommand{\\cross}{\\times}\n",
        "\\newcommand{\\F}{\\mathbf{F}}\n",
        "\\newcommand{\\M}{\\mathcal{M}}\n",
        "\\newcommand{\\bhat}{\\widehat}\n",
        "%\\newcommand{\\L}{\\mathcal{L}}\n",
        "%\\newcommand{\\span}{\\textrm{span}}\n",
        "%\\newcommand{\\null}{\\textrm{null}}\n",
        "\\newcommand{\\res}{\\textrm{Res}}\n",
        "\\newcommand{\\ds}{\\displaystyle}\n",
        "\\newcommand{\\range}{\\textrm{range}}\n",
        "$$\n",
        "# Part (a)\n",
        "### 1. Describe how the posterior predictive distribution is created for mixture models\n",
        "**Answer:** We can generate posterior predictive distribution using the following steps\n",
        "1. Based on the observations, we compute the posterior distribution of the parameters of the mixture model\n",
        "2. Given a new data point (i.e. new $\\mb x$), the predictive distribution is calculated by averaging the likelihood of $\\mb x$ under the mixture model over all possible parameter values, using the posterior distribution of the parameters as weights. Mathematically, we integrating product of the likelihood given the $\\mb x$ and the posterior distribution of the parameters over the entire parameter space. Numerically, we use MCMC to conduct a numerical integration.\n",
        "\n",
        "### 2. Describe how the posterior predictive distribution is created in general\n",
        "**Answer:** The procedure is very simular. We first compute the posterior distribution of the parameters given the observations. Let's denote it as $p(\\pmb \\theta| \\mb x, \\mb y)$. Then, the predicitve distribution is given by the following integral\n",
        "$$\n",
        "    p(y_{new}|\\mb x, \\mb y) = \\int_{\\pmb \\theta \\in \\Omega}p(y_{new}|\\pmb \\theta)p(\\pmb \\theta| \\mb x, \\mb y)\n",
        "$$\n",
        "Again, in practice, use MCMC to conduct numercial integration based on the joint pdf\n",
        "$$\n",
        "    p(y_{new}|\\pmb \\theta)p(\\pmb \\theta| \\mb x, \\mb y)\n",
        "$$\n",
        "### 3. Describe how, if you were doing a regression of $y$ on $X$ but $X$ had some missing values, you could perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
        "**Answer:** Let's denote the missing value of $X_{miss}$. Following the hint, we can assume $X_{miss}$ following some parametrized distribution. For example, we can assum $X_{miss} \\sim Uniform[0,\\theta]$, with some $\\theta$. Equivalently, this becomes the prior distribution of $X_{miss}$. With this set up, $X_{miss}$ becomes parameters that we can do Baysiean inference in the PyMC framework. Like the $\\pmb \\beta$ and intercept in the regression problem speified in Q3. For example, we can give a posterior baysian CI for these missing values using MCMC.   "
      ],
      "metadata": {
        "id": "wy9-oOebfBw0"
      }
    }
  ]
}